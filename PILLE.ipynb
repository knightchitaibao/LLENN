{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from lightning import LightningModule, Trainer\n",
    "import lightning as L\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import os\n",
    "from torch.nn import Linear, Tanh\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([50000, 256]), torch.float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = r'.\\Dataset\\datav1.pkl'\n",
    "with open(file , 'rb') as f:\n",
    "    rdata = pkl.load(f)\n",
    "\n",
    "type(rdata), rdata.shape, rdata.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 32\n",
    "if precision == 32:\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "elif precision == 64:\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "    data = rdata.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdatamin = rdata.min()\n",
    "data = torch.log10(rdata - rdatamin + 1)[::10]\n",
    "mindata = data.min()\n",
    "data = (data - data.mean())/data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lle_ds(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.nst, self.np = data.size()\n",
    "        self.np = self.np//2\n",
    "        self.slowtimes = torch.linspace(0, 1, self.nst).requires_grad_()\n",
    "        self.phases = torch.linspace(0, 1, self.np).requires_grad_()\n",
    "        self.lle_Ams = data.flatten()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nst*self.np\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx_st = index // self.np\n",
    "        idx_p = index % self.np\n",
    "        Am = (self.lle_Ams[index], self.lle_Ams[index+self.np])\n",
    "        return (self.slowtimes[idx_st], self.phases[idx_p]), Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "bs = 300\n",
    "nMLP = 32\n",
    "lMLP = 1\n",
    "loss_fn = F.mse_loss\n",
    "D2, alpha, g, Ain, D_ini, D_spd = 3.383297709479104e+06, 1.214590581942685e+07, 0.053924555862390, 2.178441699484071e+12, 1.214590581942685e+08, 9.391607661535454e+14\n",
    "zomfac_st, zomfac_p, zomfac_A = 5.173089105573258e-06, 2*torch.pi,  1\n",
    "left_paras = torch.Tensor([1/zomfac_st, D2/zomfac_p**2/2])\n",
    "right_paras = torch.Tensor([alpha, D_ini, zomfac_st*D_spd, g, Ain])\n",
    "\n",
    "trnset = lle_ds(data)\n",
    "right_paras.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(u, x, order = 1):\n",
    "    if order == 1:\n",
    "        return torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u),\n",
    "                                   create_graph=True,\n",
    "                                   only_inputs=True, allow_unused=True)[0]\n",
    "    else:\n",
    "        return gradient(gradient(u, x, order=1), x, order=order-1)\n",
    "\n",
    "def cal_loss_equ(op, loss_fn, x, y):\n",
    "    \"\"\"\n",
    "    Calculate the loss for the PINN based on the given PDEs.\n",
    "\n",
    "    Parameters:\n",
    "    - op: A tuple or list containing the predicted values of Ar and Ai from the model.\n",
    "    - loss_fn: A PyTorch loss function, such as nn.MSELoss.\n",
    "    - x: A tuple or list containing the spatial and temporal points for the PDEs.\n",
    "    - y: A tuple or list containing the true values of Ar and Ai for the PDEs.\n",
    "    - paras: A tuple or list containing the physical parameters D2, alpha, D, g, and Ain.\n",
    "    - paras: A tuple or list containing the physical parameters D2, alpha, g, Ain, D_ini, D_spd.\n",
    "    D2 = 3.383297709479104e+06, alpha = 1.214590581942685e+07, Delta = 1.214590581942685e+08, g=0.053924555862390, Ain=2.178441699484071e+12, \n",
    "    \n",
    "    Returns:\n",
    "    - The computed loss value for the PINN.\n",
    "    \"\"\"\n",
    "    #print(y)\n",
    "    opr = zomfac_A*op[:, 0] + mindata\n",
    "    opi = zomfac_A*op[:, 1] + mindata\n",
    "    Ar = zomfac_A*y[0] + mindata\n",
    "    Ai = zomfac_A*y[1] + mindata\n",
    "    #print(y[0], x[1])\n",
    "    #print('Ar', Ar, Ar.dtype, '\\nAi', Ai)\n",
    "    # zoom factor\n",
    "    left_PDEr = left_paras[0]*gradient(opr, x[0], order=1) + left_paras[1]*gradient(opi, x[1], order=2)\n",
    "    left_PDEi = left_paras[0]*gradient(opi, x[0], order=1) - left_paras[1]*gradient(opr, x[1], order=2)\n",
    "    #left_PDEi = zomfac_A/zomfac_st*gradient(op[:, 1], x[0], order=1) - (zomfac_A/zomfac_p*paras[0]/2) * gradient(op[:, 0], x[1], order=2)\n",
    "    right_PDEr = - right_paras[0] * Ar + (right_paras[1] + right_paras[2]*x[0]) * Ai - right_paras[3] * (Ar**2 + Ai**2) * Ai + right_paras[4]\n",
    "    right_PDEi = - right_paras[0] * Ai - (right_paras[1] + right_paras[2]*x[0]) * Ar + right_paras[3] * (Ar**2 + Ai**2) * Ar\n",
    "    #right_PDEr = - zomfac_A*(paras[1] * y[0] + (paras[4] + paras[5]*zomfac_st*x[0]) * y[1] - paras[2] * (y[0]**2 + y[1]**2) * y[1]) + paras[3]\n",
    "    #right_PDEi = - zomfac_A*(paras[1] * y[1] - (paras[4] + paras[5]*zomfac_st*x[0]) * y[0] + paras[2] * (y[0]**2 + y[1]**2) * y[0])\n",
    "    return loss_fn(left_PDEi.view(-1), right_PDEi) + loss_fn(left_PDEr.view(-1), right_PDEr)\n",
    "\n",
    "def cal_loss_data(op, loss_fn, y):   return loss_fn(op.view(-1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(LightningModule):\n",
    "    def __init__(self, lr=None, bs=None, \n",
    "                 nMLP=None, lMLP=None,\n",
    "                 loss_fn=None,\n",
    "                 trnset=None\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.learning_rate = lr\n",
    "        self.batch_size = bs\n",
    "\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(2, nMLP),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nMLP, nMLP),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nMLP, 2),\n",
    "        )\n",
    "        self.loss_fn = loss_fn\n",
    "        self.trnset = trnset\n",
    "\n",
    "    def forward(self, st, p):\n",
    "        bs  = st.size()\n",
    "        x = torch.cat((st.view(bs[0], 1), p.view(bs[0], 1)), dim=1)\n",
    "        MLPout = self.MLP(x)\n",
    "        #MLPout (bs, sl, freqs)\n",
    "        return MLPout\n",
    "    \n",
    "    def predict(self, x):\n",
    "        MLPout = self.MLP(x)\n",
    "        return MLPout\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (st, p), (Ar, Ai) = batch\n",
    "        op = self.forward(st, p)\n",
    "        # op (bs, 2)\n",
    "        #PDE_loss = cal_loss_equ(op, self.loss_fn, (st, p), (Ar, Ai))\n",
    "        \n",
    "        if 20 > 10:\n",
    "            loss = cal_loss_data(op[:, 0], self.loss_fn, Ar) + cal_loss_data(op[:, 1], self.loss_fn, Ai)\n",
    "        else:\n",
    "            loss = cal_loss_data(op[:, 0], self.loss_fn, Ar) + cal_loss_data(op[:, 1], self.loss_fn, Ai) + PDE_loss\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        (st, p), (Ar, Ai) = batch\n",
    "        op = self.forward(st, p)\n",
    "        # op (bs, 2)\n",
    "        loss = cal_loss_data(op[:, 0], self.loss_fn, Ar) + cal_loss_data(op[:, 1], self.loss_fn, Ai)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataloader = DataLoader(self.trnset, batch_size=self.batch_size)\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataloader = DataLoader(self.trnset, batch_size=self.batch_size)\n",
    "        return dataloader\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        from torch.optim import AdamW, Adam, SGD\n",
    "        optim = Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pmodel = PINN(lr, bs, \n",
    "                 nMLP, lMLP,\n",
    "                 loss_fn, \n",
    "                 trnset\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | MLP  | Sequential | 1.2 K  | train\n",
      "--------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\dl\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\dl\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2134/2134 [00:24<00:00, 86.80it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\dl\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(Pmodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
